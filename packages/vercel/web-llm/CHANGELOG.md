# @browser-ai/web-llm

## 2.1.2

### Patch Changes

- 7bd5bbe: feat: add webllm generation config

## 2.1.1

### Patch Changes

- 8ba3a0e: feat: add embedding model provider with WebLLMEmbeddingModel class

## 2.1.0

### Minor Changes

- acc8791: refactor: unify `createSessionWithProgress` to use a `(progress: number) => void` callback across all packages

## 2.0.4

### Patch Changes

- 0f51e16: refactor: extract shared utilities into internal @browser-ai/shared package

## 2.0.3

### Patch Changes

- f8b6996: fix: correct ESM export paths to use .mjs extension

## 2.0.2

### Patch Changes

- b20ac86: fix: structured output

## 2.0.1

### Patch Changes

- 3f665ca: chore: include hero image to npm readme

## 2.0.0

### Major Changes

- 0266287: feat: move package to @browser-ai org
